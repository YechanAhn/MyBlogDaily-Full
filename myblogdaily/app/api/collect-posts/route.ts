/**
 * ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìˆ˜ì§‘ API
 *
 * POST /api/collect-posts
 *
 * ê¸°ëŠ¥:
 * 1. RSSë¡œ í¬ìŠ¤íŠ¸ ë§í¬ ëª©ë¡ í™•ë³´
 * 2. Playwrightë¡œ ê° í¬ìŠ¤íŠ¸ ë³¸ë¬¸ í¬ë¡¤ë§
 * 3. Supabaseì— ì €ì¥
 */

import { NextRequest } from 'next/server';
import { fetchNaverBlogPosts } from '@/lib/crawler/rss-parser';
import { crawler } from '@/lib/crawler/playwright-crawler';
import { createClient } from '@/lib/supabase/server';
import { asyncHandler, Errors, ApiResponse, handleSupabaseError } from '@/lib/utils';
import { apiLogger as logger } from '@/lib/utils/logger';

/**
 * ìš”ì²­ ë°”ë”” íƒ€ì…
 */
interface CollectPostsRequest {
  userId: string;
  blogId: string;
  limit?: number;  // ìˆ˜ì§‘í•  í¬ìŠ¤íŠ¸ ìˆ˜ (ê¸°ë³¸: 50)
}

/**
 * ì‘ë‹µ íƒ€ì…
 */
interface CollectPostsResponse {
  success: true;
  collected: number;
  failed: number;
  skipped: number;  // ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í¬ìŠ¤íŠ¸
  duration: number;
  posts: Array<{
    title: string;
    url: string;
    status: 'success' | 'failed' | 'skipped';
    error?: string;
  }>;
}

/**
 * POST /api/collect-posts
 */
export const POST = asyncHandler(async (req: NextRequest) => {
  const startTime = Date.now();

  // 1. ìš”ì²­ ë°”ë”” íŒŒì‹±
  const body: CollectPostsRequest = await req.json();
  const { userId, blogId, limit = 50 } = body;

  logger.info(`ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹œì‘: ${blogId} (ì‚¬ìš©ì: ${userId}, ìµœëŒ€: ${limit}ê°œ)`);

  // 2. í•„ìˆ˜ íŒŒë¼ë¯¸í„° ê²€ì¦
  if (!userId) {
    throw Errors.BAD_REQUEST('userIdê°€ í•„ìš”í•©ë‹ˆë‹¤.');
  }

  if (!blogId) {
    throw Errors.BAD_REQUEST('blogIdê°€ í•„ìš”í•©ë‹ˆë‹¤.');
  }

  if (limit < 1 || limit > 100) {
    throw Errors.BAD_REQUEST('limitì€ 1-100 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.');
  }

  // 3. Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±
  const supabase = createClient();

  // 4. ì‚¬ìš©ì ì¡´ì¬ í™•ì¸
  const { data: user, error: userError } = await supabase
    .from('users')
    .select('id, blog_id')
    .eq('id', userId)
    .single();

  if (userError || !user) {
    logger.error(`ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: ${userId}`, userError);
    throw Errors.NOT_FOUND('ì‚¬ìš©ì');
  }

  // 5. RSSë¡œ í¬ìŠ¤íŠ¸ ë§í¬ ëª©ë¡ í™•ë³´
  logger.info(`ğŸ“¡ RSS í”¼ë“œ íŒŒì‹±: ${blogId}`);
  const rssResult = await fetchNaverBlogPosts(blogId, limit);

  if (!rssResult.success || rssResult.posts.length === 0) {
    logger.error(`RSS íŒŒì‹± ì‹¤íŒ¨: ${blogId}`, { error: rssResult.error });
    throw Errors.EXTERNAL_API_ERROR('ë„¤ì´ë²„ RSS', rssResult.error);
  }

  logger.success(`âœ… RSS íŒŒì‹± ì™„ë£Œ: ${rssResult.posts.length}ê°œ í¬ìŠ¤íŠ¸`);

  // 6. ê¸°ì¡´ í¬ìŠ¤íŠ¸ URL í™•ì¸ (ì¤‘ë³µ ì œê±°)
  const postUrls = rssResult.posts.map(p => p.link);

  const { data: existingPosts } = await supabase
    .from('blog_posts')
    .select('post_url')
    .eq('user_id', userId)
    .in('post_url', postUrls);

  const existingUrls = new Set(existingPosts?.map(p => p.post_url) || []);

  logger.info(`ğŸ“‹ ê¸°ì¡´ í¬ìŠ¤íŠ¸: ${existingUrls.size}ê°œ`);

  // 7. í¬ë¡¤ë§í•  í¬ìŠ¤íŠ¸ í•„í„°ë§
  const postsToCrawl = rssResult.posts.filter(p => !existingUrls.has(p.link));

  if (postsToCrawl.length === 0) {
    logger.warn('âš ï¸  ëª¨ë“  í¬ìŠ¤íŠ¸ê°€ ì´ë¯¸ ìˆ˜ì§‘ë¨');

    return ApiResponse.ok({
      success: true,
      collected: 0,
      failed: 0,
      skipped: existingUrls.size,
      duration: Date.now() - startTime,
      posts: []
    });
  }

  logger.info(`ğŸš€ í¬ë¡¤ë§ ì‹œì‘: ${postsToCrawl.length}ê°œ í¬ìŠ¤íŠ¸`);

  // 8. ê° í¬ìŠ¤íŠ¸ í¬ë¡¤ë§ ë° ì €ì¥
  const results: CollectPostsResponse['posts'] = [];
  let collected = 0;
  let failed = 0;

  for (const [index, rssPost] of postsToCrawl.entries()) {
    logger.info(`[${index + 1}/${postsToCrawl.length}] í¬ë¡¤ë§ ì¤‘: ${rssPost.title}`);

    try {
      // í¬ë¡¤ë§
      const crawlResult = await crawler.crawlWithRetry(rssPost.link);

      if (crawlResult.success && crawlResult.content) {
        // DB ì €ì¥
        const { error: insertError } = await supabase
          .from('blog_posts')
          .insert({
            user_id: userId,
            title: crawlResult.title || rssPost.title,
            content: crawlResult.content,
            post_url: rssPost.link,
            published_at: rssPost.pubDate,
            word_count: crawlResult.content.length,
            view_count: crawlResult.viewCount || 0,
            like_count: crawlResult.likeCount || 0,
            comment_count: crawlResult.commentCount || 0,
            is_analyzed: false
          });

        if (insertError) {
          logger.error(`DB ì €ì¥ ì‹¤íŒ¨: ${rssPost.link}`, insertError);
          failed++;
          results.push({
            title: rssPost.title,
            url: rssPost.link,
            status: 'failed',
            error: 'DB ì €ì¥ ì‹¤íŒ¨'
          });
        } else {
          collected++;
          results.push({
            title: crawlResult.title || rssPost.title,
            url: rssPost.link,
            status: 'success'
          });
          logger.success(`âœ… ì €ì¥ ì™„ë£Œ: ${crawlResult.title}`);
        }

      } else {
        failed++;
        results.push({
          title: rssPost.title,
          url: rssPost.link,
          status: 'failed',
          error: crawlResult.error
        });
        logger.error(`âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: ${rssPost.title}`, { error: crawlResult.error });
      }

    } catch (error) {
      failed++;
      results.push({
        title: rssPost.title,
        url: rssPost.link,
        status: 'failed',
        error: error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'
      });
      logger.error(`âŒ ì˜ˆì™¸ ë°œìƒ: ${rssPost.title}`, error);
    }
  }

  // 9. í¬ë¡¤ëŸ¬ ì¢…ë£Œ
  await crawler.closeBrowser();

  const duration = Date.now() - startTime;
  const successRate = ((collected / postsToCrawl.length) * 100).toFixed(1);

  logger.success(
    `ğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ: ${collected}ê°œ ì„±ê³µ, ${failed}ê°œ ì‹¤íŒ¨, ${existingUrls.size}ê°œ ìŠ¤í‚µ (${duration}ms, ì„±ê³µë¥ : ${successRate}%)`
  );

  // 10. ì‘ë‹µ ë°˜í™˜
  return ApiResponse.ok({
    success: true,
    collected,
    failed,
    skipped: existingUrls.size,
    duration,
    posts: results
  } as CollectPostsResponse);
});
